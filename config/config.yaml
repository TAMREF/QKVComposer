model:
  d_ff: 256
  d_hidden: 256
  d_embed: 256
  dropout: 0.1
  data_len: 1024
  num_time_token: 400
  n_head: 4
  num_layers: 6
  num_tokens: 385
  padding_idx: 384
  use_temporal_encoding: True

log:
  checkpoint_dir: 'checkpoints'
  log_dir: 'logs'
  name: 'test'
  trace: False
  version: 0

data:
  datamidi_dir: 'dataset/midi'
  dataset_path: ''
  make_note_tensor: False
  max_len: 1000000
  notetensor_dir: 'dataset/note_tensor'
  num_workers: 0

train:
  accumulate: 1
  batch_size: 16
  betas: [0.5, 0.9]
  epochs: 1500
  fast_dev_run: False
  gpus: 1
  lr: 0.0003
  optim: 'adam'
  resume: 'outputs\2021-02-03\02-09-40\checkpoints\ckpt-epoch=0063-val_loss=6.2563.ckpt'
  save_top_k: 3
  steps: 100
  time_loss_mode: 'one_hot'
  time_loss_mul: 1.0
  valid_split: 1024

inference:
  length: 3000
  condition_pt:
  checkpoint_path: 'outputs\2021-02-03\02-09-40\checkpoints\ckpt-epoch=0063-val_loss=6.2563.ckpt'
  sample: False
  save_path: 'samples'
  sample_mode: 'OneHotCategorical'